import os
import json
from glob import glob
from PIL import Image
from torchvision import transforms
import torch

class SequenceDataset(torch.utils.data.Dataset):
    def __init__(self, json_root_dir, image_root_dir, label_map, transform=None, action2idx=None, use_face=True):
        self.samples = []
        self.transform = transform
        self.label_map = label_map
        self.action2idx = action2idx
        self.use_face = use_face

        json_files = glob(os.path.join(json_root_dir, "**", "*.json"), recursive=True)
        print(f"ğŸ” ì´ JSON íŒŒì¼ ìˆ˜: {len(json_files)}")

        for json_path in json_files:
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                category = data.get("scene_info", {}).get("category_name")
                if category not in label_map:
                    continue

                label = label_map[category]
                frames = data.get("scene", {}).get("data", [])
                # í”„ë ˆì„ì´ ê¼­ 5ê°œì—¬ì•¼ í•˜ëŠ” ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€
                if len(frames) != 5:
                    continue

                # JSON ê²½ë¡œ â†’ image í´ë” ë‚´ë¶€ ê²½ë¡œ ê³„ì‚°
                rel_path = os.path.relpath(os.path.dirname(json_path), json_root_dir)
                rel_path = rel_path.replace("label", "").rstrip("/\\")
                
                # lazy loadingì„ ìœ„í•´ "ì´ë¯¸ì§€ ê²½ë¡œì™€ bboxë§Œ" ì €ì¥
                img_paths = []
                bboxes = []
                actions = []

                valid_frames = True
                for frame in frames:
                    img_name = frame.get("img_name")
                    img_path = os.path.join(image_root_dir, rel_path, "img", img_name)
                    if not os.path.exists(img_path):
                        valid_frames = False
                        break

                    occupant = frame.get("occupant", [])
                    if not occupant:
                        valid_frames = False
                        break
                    
                    occupant_0 = occupant[0]
                    bbox = occupant_0.get("face_b_box") if self.use_face else occupant_0.get("body_b_box")
                    if not bbox or len(bbox) != 4:
                        valid_frames = False
                        break

                    img_paths.append(img_path)
                    bboxes.append(bbox)
                    actions.append(occupant_0.get("action", "ê¸°íƒ€"))

                if not valid_frames:
                    continue

                # 5ì¥ ëª¨ë‘ ìœ íš¨í•˜ë©´, ê°€ì¥ ë§ì´ ë‚˜ì˜¨ action í•˜ë‚˜ë¥¼ top_actionìœ¼ë¡œ
                action_counts = {a: actions.count(a) for a in actions}
                top_action = max(action_counts, key=action_counts.get)

                # **ì¤‘ìš”**: ì—¬ê¸°ì„  ì´ë¯¸ì§€ ì—´ì§€ ì•Šê³ , í•„ìš”í•œ ì •ë³´ë§Œ ì €ì¥
                self.samples.append({
                    "img_paths": img_paths,     # [str, str, str, str, str]
                    "bboxes": bboxes,          # [(x,y,w,h), (x,y,w,h), ...]
                    "label": label,
                    "top_action": top_action
                })

            except Exception as e:
                print(f"âš ï¸ {json_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        """ ì‹¤ì œë¡œ ì´ë¯¸ì§€ íŒŒì¼ ì—´ê³ , crop & transform ì ìš© (lazy loading) """
        sample = self.samples[idx]
        img_paths = sample["img_paths"]
        
        
        s = sample["bboxes"]
        label = sample["label"]
        top_action = sample["top_action"]

        seq_imgs = []
        for (img_path, bbox) in zip(img_paths, sample["bboxes"]):
            x, y, w, h = bbox

            try:
                with Image.open(img_path).convert('RGB') as img:
                    crop = img.crop((x, y, x + w, y + h))
                    if self.transform:
                        crop = self.transform(crop)
                    seq_imgs.append(crop)
            except:
                # ë§Œì•½ ì—¬ê¸°ì„œ ì´ë¯¸ì§€ ê¹¨ì§ ë“±ì˜ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ None ë¦¬í„´ or ì˜ˆì™¸ ì²˜ë¦¬
                # ë³´í†µì€ ì´ ìƒ˜í”Œì„ ê±´ë„ˆë›°ê±°ë‚˜, dummy tensorë¡œ ëŒ€ì²´í•  ìˆ˜ë„ ìˆìŒ
                # ì˜ˆì‹œë¡œ ê·¸ëƒ¥ ì˜¤ë¥˜ ë°œìƒì‹œí‚¤ê¸°:
                return None

        # seq_imgsë¥¼ í•˜ë‚˜ì˜ í…ì„œë¡œ ë¬¶ì–´ì„œ ë°˜í™˜
        seq_imgs = torch.stack(seq_imgs)  # shape: [5, C, H, W]
        return seq_imgs, label, top_action
