import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os
import json
import glob
from sklearn.model_selection import train_test_split
import cv2
import dlib
import pyrealsense2 as rs
import numpy as np

if torch.cuda.is_available():
    torch.set_default_device("cuda")

# âœ… GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.backends.cudnn.benchmark = True  # âœ… CNN ëª¨ë¸ ì„±ëŠ¥ ìµœì í™”
torch.cuda.empty_cache()  # âœ… ë¶ˆí•„ìš”í•œ ìºì‹œ ì •ë¦¬

print(f"ğŸ’» Using device: {device}")
torch.backends.cudnn.benchmark = True  # âœ… GPU ì„±ëŠ¥ ìµœì í™”
torch.cuda.empty_cache()  # âœ… GPU ìºì‹œ ì •ë¦¬

# âœ… Dlib ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ
detector = dlib.get_frontal_face_detector()

# âœ… RealSense ì„¤ì • (RGB ìŠ¤íŠ¸ë¦¼ë§Œ ì‚¬ìš©)
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)  # RGB ìŠ¤íŠ¸ë¦¼ë§Œ í™œì„±í™”
pipeline.start(config)

def detect_faces():
    """ RealSense ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ë°›ì•„ ì–¼êµ´ì„ ê²€ì¶œí•˜ê³  ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ """
    frames = pipeline.wait_for_frames()
    color_frame = frames.get_color_frame()
    
    if not color_frame:
        return None, None

    # RGB ì´ë¯¸ì§€ ë³€í™˜
    color_image = np.asanyarray(color_frame.get_data())
    gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)

    # ì–¼êµ´ ê²€ì¶œ
    faces = detector(gray)

    return color_image, faces  # (ì´ë¯¸ì§€, ì–¼êµ´ ë¦¬ìŠ¤íŠ¸) ë°˜í™˜

def release_camera():
    """ ì¹´ë©”ë¼ ì¢…ë£Œ í•¨ìˆ˜ """
    pipeline.stop()

# âœ… ë°ì´í„° ë¡œë“œ
json_dir = "C:/data/json"  # JSON íŒŒì¼ ê²½ë¡œ
image_dir = "C:/data/image"  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ

def load_json_labels(json_dir, image_dir):
    json_files = glob.glob(os.path.join(json_dir, "**", "*.json"), recursive=True)
    print(f"ğŸ“‚ Found {len(json_files)} JSON files")

    dataset = []
    for json_file in json_files:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        image_name = data.get("FileInfo", {}).get("FileName")  
        relative_path = os.path.relpath(json_file, json_dir)  
        image_path = os.path.join(image_dir, relative_path).replace("\\", "/")  
        image_path = image_path.rsplit(".", 1)[0] + ".jpg"  

        exists = os.path.exists(image_path)  
        if exists:
            dataset.append((json_file, image_path, data))

    print(f"âœ… Loaded {len(dataset)} items")
    if len(dataset) == 0:
        raise ValueError("ğŸš¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤! JSON ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    return dataset

data = load_json_labels(json_dir, image_dir)

# âœ… ë°ì´í„°ì…‹ ë¶„í• 
train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)
print(f"âœ… Train dataset size: {len(train_data)}")
print(f"âœ… Validation dataset size: {len(val_data)}")

# âœ… ì´ë¯¸ì§€ ë³€í™˜ ì •ì˜
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# âœ… ë°ì´í„°ì…‹ ì •ì˜
class DrowsinessDataset(Dataset):
    def __init__(self, data, transform=None):
        self.data = [(img_path, metadata_dict['Annotation']) for json_path, img_path, metadata_dict in data if os.path.exists(img_path)]
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path, label = self.data[idx]
        try:
            image = Image.open(img_path).convert('RGB')
        except (OSError, IOError):
            print(f"ğŸš¨ Skipping corrupted image: {img_path}")
            return None  

        if self.transform:
            image = self.transform(image)

        return image, label 

def collate_fn(batch):
    batch = [item for item in batch if item is not None]  
    return torch.utils.data.default_collate(batch) if batch else None  

train_dataset = DrowsinessDataset(train_data, transform=transform)
val_dataset = DrowsinessDataset(val_data, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, 
                          collate_fn=collate_fn, pin_memory=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, 
                        collate_fn=collate_fn, pin_memory=True, num_workers=4)

# âœ… CNN + LSTM ëª¨ë¸ ì •ì˜
class DrowsinessModel(nn.Module):
    def __init__(self):
        super(DrowsinessModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.lstm = nn.LSTM(16 * 64 * 64, 128, batch_first=True)
        self.fc1 = nn.Linear(128, 2)
    
    def forward(self, x):
        batch_size, seq_len, C, H, W = x.shape
        x = x.view(batch_size * seq_len, C, H, W)
        x = self.pool(self.relu(self.conv1(x)))
        x = x.view(batch_size, seq_len, -1)
        x, _ = self.lstm(x)
        x = self.fc1(x[:, -1, :])
        return x

# âœ… ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def train_model(model, train_loader, val_loader, epochs=5, lr=0.001):
    criterion = nn.CrossEntropyLoss().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device).long()
            images = images.unsqueeze(1)  

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}')
    
    torch.save(model.state_dict(), 'model.pth')
    print("âœ… Model training complete and saved!")

model = DrowsinessModel().to(device)
train_model(model, train_loader, val_loader)

print(f"GPU ì‚¬ìš© ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated(device) / 1024 / 1024:.2f} MB")
print(f"GPU ìºì‹œ ë©”ëª¨ë¦¬: {torch.cuda.memory_reserved(device) / 1024 / 1024:.2f} MB")
