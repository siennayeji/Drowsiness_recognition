import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os
import json
import glob
from sklearn.model_selection import train_test_split

# ë°ì´í„° ë¡œë“œ
json_dir = "C:/data/json"  # JSON íŒŒì¼ ê²½ë¡œ
image_dir = "C:/data/image"  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ

def load_json_labels(json_dir, image_dir):
    json_files = glob.glob(os.path.join(json_dir, "**", "*.json"), recursive=True)
    print(f"ğŸ“‚ Found {len(json_files)} JSON files")

    dataset = []
    for json_file in json_files:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        image_name = data.get("FileInfo", {}).get("FileName")  # JSONì— ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ëª…
        relative_path = os.path.relpath(json_file, json_dir)  # JSON ê²½ë¡œ ìƒëŒ€ ê²½ë¡œ ë³€í™˜
        image_path = os.path.join(image_dir, relative_path).replace("\\", "/")  # json -> image ë³€ê²½
        image_path = image_path.rsplit(".", 1)[0] + ".jpg"  # í™•ì¥ì ë³€ê²½
        
        exists = os.path.exists(image_path)  # ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

        if exists:
            dataset.append((json_file, image_path, data))

    print(f"âœ… Loaded {len(dataset)} items")
    if len(dataset) == 0:
        raise ValueError("ğŸš¨ ëª¨ë“  ë°ì´í„°ê°€ ì†ì‹¤ë˜ì—ˆìŠµë‹ˆë‹¤! JSON ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    return dataset

data = load_json_labels(json_dir, image_dir)

# âœ… ë°ì´í„°ì…‹ì´ ë¹„ì–´ ìˆëŠ”ì§€ í™•ì¸
if len(data) == 0:
    raise ValueError("ğŸš¨ ë°ì´í„°ì…‹ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤! JSON ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

print(f"ğŸ“Œ Loaded {len(data)} items")

# ë°ì´í„° ë¶„í• 
train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)

# âœ… í›ˆë ¨ / ê²€ì¦ ë°ì´í„° ê°œìˆ˜ í™•ì¸
print(f"âœ… Train dataset size: {len(train_data)}")
print(f"âœ… Validation dataset size: {len(val_data)}")

if len(train_data) == 0:
    raise ValueError("ğŸš¨ í›ˆë ¨ ë°ì´í„°ì…‹ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤! ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if len(val_data) == 0:
    raise ValueError("ğŸš¨ ê²€ì¦ ë°ì´í„°ì…‹ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤! ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# ì´ë¯¸ì§€ ë³€í™˜ ì •ì˜
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# ë°ì´í„°ì…‹ ì •ì˜
class DrowsinessDataset(Dataset):
    def __init__(self, data, transform=None):
        self.data = [(img_path, metadata_dict['Annotation']) for json_path, img_path, metadata_dict in data if os.path.exists(img_path)]
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path, label = self.data[idx]
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, label
    
print(f"ğŸ” ë°ì´í„° êµ¬ì¡° í™•ì¸: {data[:5]}")

# DataLoader ì„¤ì •
def collate_fn(batch):
    batch = [item for item in batch if item is not None]  # None ê°’ ì œê±°
    return torch.utils.data.default_collate(batch) if batch else None  # ë¹ˆ ë°°ì¹˜ ë°©ì§€

train_dataset = DrowsinessDataset(train_data, transform=transform)
val_dataset = DrowsinessDataset(val_data, transform=transform)

# âœ… train_datasetì´ ë¹„ì–´ ìˆëŠ” ê²½ìš° ì—ëŸ¬ ë°©ì§€
if len(train_dataset) == 0:
    raise ValueError("ğŸš¨ train_datasetì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤! JSONê³¼ ì´ë¯¸ì§€ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)

# ëª¨ë¸ ì •ì˜
class DrowsinessModel(nn.Module):
    def __init__(self):
        super(DrowsinessModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(16 * 64 * 64, 2)

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        return x

# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def train_model(model, train_loader, val_loader, epochs=5, lr=0.001):
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    
    for epoch in range(epochs):
        model.train()
        total_loss = 0

        for images, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, torch.tensor(labels, dtype=torch.long))
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels in val_loader:
                outputs = model(images)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        print(f'ğŸ“¢ Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')
    
    torch.save(model.state_dict(), 'model.pth')
    print("âœ… Model training complete and saved.")

# ëª¨ë¸ í•™ìŠµ ìˆ˜í–‰
model = DrowsinessModel()
train_model(model, train_loader, val_loader)
