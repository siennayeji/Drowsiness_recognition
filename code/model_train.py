import torch
import torchvision.transforms as transforms
import pandas as pd
import cv2
import numpy as np
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from sklearn.metrics import accuracy_score

# âœ… í•œê¸€ íŒŒì¼ëª…ì„ ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ ë¡œë“œ í•¨ìˆ˜
def imread_unicode(img_path):
    try:
        img_array = np.fromfile(img_path, np.uint8)  # í•œê¸€ ê²½ë¡œ ì§€ì›
        image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        return image
    except Exception as e:
        print(f"ğŸš¨ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}, ì˜¤ë¥˜: {e}")
        return None

# âœ… ë°ì´í„° ì¦ê°• ì„¤ì • (0,1 í´ë˜ìŠ¤ë§Œ ì ìš©)
augment_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.RandomHorizontalFlip(p=0.5),  # ì¢Œìš° ë°˜ì „
    transforms.RandomRotation(10),          # íšŒì „
    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # ë°ê¸° & ëŒ€ë¹„ ë³€ê²½
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# âœ… ì¼ë°˜ ë³€í™˜ (ì¦ê°• X)
base_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# ğŸ“Œ Custom Dataset
class DrowsinessDataset(Dataset):
    def __init__(self, csv_file, transform=None):
        self.data = pd.read_csv(csv_file)
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path = self.data.iloc[idx]['ImagePath']
        label = int(self.data.iloc[idx]['Label'])

        # âœ… í•œê¸€ ê²½ë¡œ ì§€ì›í•˜ëŠ” í•¨ìˆ˜ë¡œ ì´ë¯¸ì§€ ë¡œë“œ
        image = imread_unicode(img_path)

        if image is None:
            print(f"ğŸš¨ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
            return self.__getitem__((idx + 1) % len(self.data))  # ë‹¤ë¥¸ ìƒ˜í”Œë¡œ ëŒ€ì²´

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # âœ… í•˜í’ˆ(0), ì¡¸ìŒ(1) ë°ì´í„°ë§Œ ì¦ê°• ì ìš©
        if label in [0, 1]:
            image = augment_transform(image)
        else:
            image = base_transform(image)

        return image, label

# ğŸ“Œ DataLoader ì„¤ì •
train_dataset = DrowsinessDataset("train.csv")
val_dataset = DrowsinessDataset("val.csv")

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

# ğŸ“Œ CNN + LSTM ëª¨ë¸
class DrowsinessModel(nn.Module):
    def __init__(self):
        super(DrowsinessModel, self).__init__()

        # CNN ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
            
        )

        # Fully Connected Layer (LSTM ëŒ€ì‹ )
        self.fc = nn.Sequential(
            nn.Linear(64 * 28 * 28, 256),
            nn.ReLU(),
            nn.Linear(256, 3)  # 3ê°œ í´ë˜ìŠ¤ (í•˜í’ˆ, ì¡¸ìŒ, ì •ìƒ)
        )

    def forward(self, x):
        x = self.cnn(x)  # CNN íŠ¹ì§• ì¶”ì¶œ
        x = x.view(x.size(0), -1)  # Flatten
        x = self.fc(x)  # FC Layerë¡œ ë¶„ë¥˜
        return x

# ğŸ“Œ í•™ìŠµ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DrowsinessModel().to(device)

# ì†ì‹¤ í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì €
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ğŸ“Œ í•™ìŠµ ë£¨í”„
num_epochs = 10 # ì›í•˜ëŠ” ì—í¬í¬ ìˆ˜ ì„¤ì •
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"ğŸ”¹ Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}")

print("ğŸ¯ í•™ìŠµ ì™„ë£Œ!")
# ğŸ“Œ í•™ìŠµëœ ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "drowsiness_model_1.pth")
print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: drowsiness_model_1.pth")

# ëª¨ë¸ í‰ê°€ ëª¨ë“œ
model.eval()
y_true, y_pred = [], []

with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

# ì •í™•ë„ ê³„ì‚°
accuracy = accuracy_score(y_true, y_pred)
print(f"âœ… Validation Accuracy: {accuracy * 100:.2f}%")