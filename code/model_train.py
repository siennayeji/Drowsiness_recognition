import torch
import torchvision.transforms as transforms
import pandas as pd
import cv2
import numpy as np
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from sklearn.metrics import accuracy_score

# âœ… í•œê¸€ íŒŒì¼ëª…ì„ ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ ë¡œë“œ í•¨ìˆ˜
def imread_unicode(img_path):
    try:
        img_array = np.fromfile(img_path, np.uint8)  # í•œê¸€ ê²½ë¡œ ì§€ì›
        image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        return image
    except Exception as e:
        print(f"ğŸš¨ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}, ì˜¤ë¥˜: {e}")
        return None

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# ğŸ“Œ Custom Dataset
class DrowsinessDataset(Dataset):
    def __init__(self, csv_file, transform=None):
        self.data = pd.read_csv(csv_file)
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path = self.data.iloc[idx]['ImagePath']
        label = int(self.data.iloc[idx]['Label'])

        # âœ… í•œê¸€ ê²½ë¡œ ì§€ì›í•˜ëŠ” í•¨ìˆ˜ë¡œ ì´ë¯¸ì§€ ë¡œë“œ
        image = imread_unicode(img_path)

        if image is None:
            print(f"ğŸš¨ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
            return self.__getitem__((idx + 1) % len(self.data))  # ë‹¤ë¥¸ ìƒ˜í”Œë¡œ ëŒ€ì²´

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        if self.transform:
            image = self.transform(image)

        return image, label

# ğŸ“Œ DataLoader ì„¤ì •
train_dataset = DrowsinessDataset("train.csv", transform=transform)
val_dataset = DrowsinessDataset("val.csv", transform=transform)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

# ğŸ“Œ CNN + LSTM ëª¨ë¸
class DrowsinessModel(nn.Module):
    def __init__(self):
        super(DrowsinessModel, self).__init__()

        # CNN ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )

        # LSTM (ì‹œê³„ì—´ í•™ìŠµ)
        self.lstm = nn.LSTM(input_size=64 * 28 * 28, hidden_size=128, num_layers=1, batch_first=True)

        # ìµœì¢… ë¶„ë¥˜ê¸°
        self.fc = nn.Linear(128, 3)  # 3ê°œì˜ í´ë˜ìŠ¤ (í•˜í’ˆ, ì¡¸ìŒ, ì •ìƒ)

    def forward(self, x):
        batch_size = x.size(0)
        
        # CNN íŠ¹ì§• ì¶”ì¶œ
        x = self.cnn(x)
        x = x.view(batch_size, 1, -1)  # LSTM ì…ë ¥ì„ ìœ„í•œ í˜•íƒœ ë³€í™˜
        
        # LSTM í•™ìŠµ
        x, _ = self.lstm(x)

        # ìµœì¢… ë¶„ë¥˜
        x = self.fc(x[:, -1, :])
        return x

# ğŸ“Œ í•™ìŠµ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DrowsinessModel().to(device)

# ì†ì‹¤ í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì €
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ğŸ“Œ í•™ìŠµ ë£¨í”„
num_epochs = 5 # ì›í•˜ëŠ” ì—í¬í¬ ìˆ˜ ì„¤ì •
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"ğŸ”¹ Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}")

print("ğŸ¯ í•™ìŠµ ì™„ë£Œ!")
# ğŸ“Œ í•™ìŠµëœ ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "drowsiness_model.pth")
print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: drowsiness_model.pth")

# ëª¨ë¸ í‰ê°€ ëª¨ë“œ
model.eval()
y_true, y_pred = [], []

with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

# ì •í™•ë„ ê³„ì‚°
accuracy = accuracy_score(y_true, y_pred)
print(f"âœ… Validation Accuracy: {accuracy * 100:.2f}%")