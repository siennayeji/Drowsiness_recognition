# âœ… CNN + LSTM í•™ìŠµ ì½”ë“œ (ê²½ë¡œ ë¬¸ì œ í•´ê²° + ë°ì´í„° ì¦ê°• + ê²€ì¦ ì •í™•ë„ í¬í•¨)

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
from data_labeling import SequenceDataset
from glob import glob
from collections import Counter
import json

# í•˜ì´í¼íŒŒë¼ë¯¸í„°
BATCH_SIZE = 8
EPOCHS = 10
SEQ_LEN = 5
NUM_CLASSES = 2  # ì¡¸ìŒ: 1, ì •ìƒ: 0

# ì£¼ìš” í–‰ë™ ë¦¬ìŠ¤íŠ¸
action_vocab = [
    "í•˜í’ˆ", "ê¾¸ë²…ê¾¸ë²…ì¡¸ë‹¤", "ëˆˆë¹„ë¹„ê¸°", "ëˆˆê¹œë¹¡ì´ê¸°", "ì „ë°©ì£¼ì‹œ", "ìš´ì „í•˜ë‹¤", "ê¸°íƒ€"
]
action2idx = {a: i for i, a in enumerate(action_vocab)}
ACTION_DIM = len(action_vocab)

# ë¼ë²¨ ë§¤í•‘
label_map = {
    "ì¡¸ìŒìš´ì „": 1,
    "ìŒì£¼ìš´ì „": 0,
    "ë¬¼ê±´ì°¾ê¸°": 0,
    "í†µí™”": 0,
    "íœ´ëŒ€í°ì¡°ì‘": 0,
    "ì°¨ëŸ‰ì œì–´": 0,
    "ìš´ì „ìí­í–‰": 0
}

# ì „ì²˜ë¦¬ ì •ì˜
basic_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

aug_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# ë°ì´í„° ê²½ë¡œ
json_root_dir = "C:/data/json"
image_root_dir = "C:/data/image"

# ë°ì´í„° í™•ì¸
json_files = glob(os.path.join(json_root_dir, "**", "*.json"), recursive=True)
image_files = glob(os.path.join(image_root_dir, "**", "*.jpg"), recursive=True)
print(f"ğŸ“ JSON íŒŒì¼ ê°œìˆ˜: {len(json_files)}")
print(f"ğŸ“ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(image_files)}")

# ë°ì´í„°ì…‹ ìƒì„±
print("ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")
try:
    full_dataset = SequenceDataset(
        json_root_dir=json_root_dir,
        image_root_dir=image_root_dir,
        label_map=label_map,
        transform=basic_transform,
        action2idx=action2idx,
        use_face=True
    )
    print("ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
except Exception as e:
    print(f"ë°ì´í„°ì…‹ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    import traceback
    traceback.print_exc()
    exit()

print("ë°ì´í„°ì…‹ ê¸¸ì´:", len(full_dataset))
print(f"\nğŸ“Š ìœ íš¨í•œ ì‹œí€€ìŠ¤ ìˆ˜ (Dataset í¬ê¸°): {len(full_dataset)}")
if len(full_dataset) == 0:
    print("âŒ ìœ íš¨í•œ ì‹œí€€ìŠ¤ê°€ 0ê°œì…ë‹ˆë‹¤. JSONê³¼ ì´ë¯¸ì§€ ê²½ë¡œ, êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# ë¼ë²¨ ë¶„í¬ ì¶œë ¥
labels = []
for i in range(len(full_dataset)):
    item = full_dataset[i]
    if item is None:
        continue
    _, label, _ = item
    labels.append(label)
print("ğŸ“Š ë¼ë²¨ ë¶„í¬:", Counter(labels))

# ë°ì´í„° ë¶„í• 
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# collate_fn ì •ì˜
def skip_broken_collate_fn(batch):
    filtered = [item for item in batch if item is not None]
    if len(filtered) == 0:
        return None, None, None
    seqs, labels, actions = zip(*filtered)
    seqs = torch.stack(seqs, dim=0)
    labels = torch.tensor(labels, dtype=torch.long)
    return seqs, labels, actions

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=skip_broken_collate_fn)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=skip_broken_collate_fn)
print(f"Train DataLoader Length: {len(train_loader)}")

# ëª¨ë¸ ì •ì˜
class CNNEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 16, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, 1, 1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))
        )

    def forward(self, x):
        x = self.cnn(x)
        return x.view(x.size(0), -1)

class DrowsinessCNNLSTM(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = CNNEncoder()
        self.lstm = nn.LSTM(input_size=64, hidden_size=128, batch_first=True)
        self.fc = nn.Linear(128 + ACTION_DIM, NUM_CLASSES)

    def forward(self, x, action_vec):
        B, T, C, H, W = x.shape
        x = x.view(B * T, C, H, W)
        feats = self.encoder(x)
        feats = feats.view(B, T, -1)
        out, _ = self.lstm(feats)
        out = out[:, -1, :]
        out = torch.cat([out, action_vec], dim=1)
        return self.fc(out)

# í•™ìŠµ ë£¨í”„

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DrowsinessCNNLSTM().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(EPOCHS):
    model.train()
    total_loss = 0
    count = 0

    for seqs, labels, actions in train_loader:
        if seqs is None:
            continue
        seqs, labels = seqs.to(device), labels.to(device)
        action_idx = [action2idx.get(a, action2idx["ê¸°íƒ€"]) for a in actions]
        action_vec = torch.nn.functional.one_hot(torch.tensor(action_idx), num_classes=ACTION_DIM).float().to(device)

        optimizer.zero_grad()
        outputs = model(seqs, action_vec)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        count += 1

    # ê²€ì¦ ë£¨í”„
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for seqs, labels, actions in val_loader:
            if seqs is None:
                continue
            seqs, labels = seqs.to(device), labels.to(device)
            action_idx = [action2idx.get(a, action2idx["ê¸°íƒ€"]) for a in actions]
            action_vec = torch.nn.functional.one_hot(torch.tensor(action_idx), num_classes=ACTION_DIM).float().to(device)
            outputs = model(seqs, action_vec)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    acc = correct / total if total > 0 else 0
    print(f"âœ… Epoch [{epoch+1}/{EPOCHS}] Loss: {total_loss/count:.4f} | Val Acc: {acc:.4f}")

# ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "cnn_lstm_drowsiness_1.pth")
print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")